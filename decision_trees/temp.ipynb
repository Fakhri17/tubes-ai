{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class DecisionTreeClassifierScratch:\n",
    "#   def __init__(self, max_depth=None):\n",
    "#     self.max_depth = max_depth\n",
    "#     self.tree = None\n",
    "\n",
    "#   def fit(self, X, y):\n",
    "#     self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "#   def predict(self, X):\n",
    "#     predictions = []\n",
    "#     for sample in X:\n",
    "#       predictions.append(self._traverse_tree(sample, self.tree))\n",
    "#     return np.array(predictions)\n",
    "\n",
    "#   def _build_tree(self, X, y, depth):\n",
    "#     if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "#       return self._create_leaf_node(y)\n",
    "\n",
    "#     best_split_feature, best_split_value = self._find_best_split(X, y)\n",
    "#     left_indices = X[:, best_split_feature] <= best_split_value\n",
    "#     right_indices = X[:, best_split_feature] > best_split_value\n",
    "\n",
    "#     left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "#     right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "#     return {\n",
    "#       'feature_index': best_split_feature,\n",
    "#       'split_value': best_split_value,\n",
    "#       'left': left_subtree,\n",
    "#       'right': right_subtree\n",
    "#     }\n",
    "\n",
    "#   def _find_best_split(self, X, y):\n",
    "#     best_gini = float('inf')\n",
    "#     best_split_feature = None\n",
    "#     best_split_value = None\n",
    "\n",
    "#     for feature_index in range(X.shape[1]):\n",
    "#       unique_values = np.unique(X[:, feature_index])\n",
    "#       for value in unique_values:\n",
    "#         gini = self._calculate_gini_index(X, y, feature_index, value)\n",
    "#         if gini < best_gini:\n",
    "#           best_gini = gini\n",
    "#           best_split_feature = feature_index\n",
    "#           best_split_value = value\n",
    "\n",
    "#     return best_split_feature, best_split_value\n",
    "\n",
    "#   def _calculate_gini_index(self, X, y, feature_index, split_value):\n",
    "#     left_indices = X[:, feature_index] <= split_value\n",
    "#     right_indices = X[:, feature_index] > split_value\n",
    "\n",
    "#     left_labels = y[left_indices]\n",
    "#     right_labels = y[right_indices]\n",
    "\n",
    "#     left_gini = self._calculate_gini_impurity(left_labels)\n",
    "#     right_gini = self._calculate_gini_impurity(right_labels)\n",
    "\n",
    "#     left_weight = len(left_labels) / len(y)\n",
    "#     right_weight = len(right_labels) / len(y)\n",
    "\n",
    "#     return (left_weight * left_gini) + (right_weight * right_gini)\n",
    "\n",
    "#   def _calculate_gini_impurity(self, labels):\n",
    "#     _, counts = np.unique(labels, return_counts=True)\n",
    "#     probabilities = counts / len(labels)\n",
    "#     gini_impurity = 1 - np.sum(probabilities ** 2)\n",
    "#     return gini_impurity\n",
    "\n",
    "#   def _create_leaf_node(self, y):\n",
    "#     unique_labels, counts = np.unique(y, return_counts=True)\n",
    "#     majority_label = unique_labels[np.argmax(counts)]\n",
    "#     return {'label': majority_label}\n",
    "\n",
    "#   def _traverse_tree(self, sample, node):\n",
    "#     if 'label' in node:\n",
    "#       return node['label']\n",
    "\n",
    "#     if sample[node['feature_index']] <= node['split_value']:\n",
    "#       return self._traverse_tree(sample, node['left'])\n",
    "#     else:\n",
    "#       return self._traverse_tree(sample, node['right'])\n",
    "    \n",
    "#   # best model\n",
    "# dtree_scratch = DecisionTreeClassifierScratch(max_depth=3)\n",
    "# dtree_scratch.fit(X_train.values, y_train)\n",
    "# y_pred_scratch = dtree_scratch.predict(X_test.values)\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1_score(y_test, y_pred_scratch, average='weighted')\n",
    "# print(\"Decision Tree Scratch F1 Score: \"+str(f1_score(y_test, y_pred_scratch, average='weighted')))\n",
    "# print(\"Decision Tree Test F1 Score: \"+str(m.score(X_test,y_test)))\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, y_pred_scratch))\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y_test, y_pred_scratch)\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
